{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"t-sne_empty.ipynb","provenance":[{"file_id":"1qa3qKAKb0JB6Tm1QLYbRXTL-NImfY3zt","timestamp":1594854768295}],"collapsed_sections":[],"authorship_tag":"ABX9TyNKSTrzGsjHBUfwfgxvUyKl"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"bB9GTAdEaZ8O","colab_type":"text"},"source":["## t-distributed Stochastic Neighbor Embedding (t-SNE)\n","\n","https://distill.pub/2016/misread-tsne/\n","\n","Jáá sabemos que é necessário reduzir a dimensionalidade da entrada para evitar o problema da **maldição de entrada**. \n","\n","O t-SNE, não apenas reduz a dimensão do conjunto de dados para facilitar a análise e a visualizaçãão, mas também preserva a \"geometria\" do conjunto de dados. \n","\n","A classe de algoritmos de redução de dimensionalidade que exploram a geometria dos dados e a utilizam para criar uma função de mapeamento $\\Phi()$ é conhecida como **manifold learning**.\n","\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"CQh4mFxRntqx","colab_type":"text"},"source":["Sklearn documentation:\n","\n","t-SNE is a tool to visualize high-dimensional data. It converts similarities between data points to joint probabilities and tries to minimize the Kullback-Leibler divergence between the joint probabilities of the low-dimensional embedding and the high-dimensional data. t-SNE has a cost function that is not convex, i.e. **with different initializations we can get different results**.\n","\n","**It is highly recommended to use another dimensionality reduction method** (e.g. PCA for dense data or TruncatedSVD for sparse data) **to reduce the number of dimensions to a reasonable amount** (e.g. 50) **if the number of features is very high**. This will suppress some noise and speed up the computation of pairwise distances between samples."]},{"cell_type":"code","metadata":{"id":"gHutlSRQV5kL","colab_type":"code","colab":{}},"source":["# import numpy as np\n","# from sklearn.datasets import load_digits\n","# from sklearn.manifold import TSNE\n","\n","# import matplotlib.pyplot as plt\n","# %matplotlib inline\n","\n","# import seaborn as sns\n","# palette = sns.color_palette(\"bright\", 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IKv4T5WWnLr3","colab_type":"code","colab":{}},"source":["# X, y = load_digits(return_X_y=True)\n","# print(X.shape)\n","# y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLAfVVvCvPTK","colab_type":"code","colab":{}},"source":["# plt.figure(figsize=(2,2))\n","# plt.imshow(X[0,:].reshape(8,8))\n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RTBvmTrVniGC","colab_type":"code","colab":{}},"source":["# plt.figure(figsize=(20,5))\n","\n","# for i in range(10):\n","#     ax = plt.subplot(2,5,i+1)\n","#     ax.set_axis_off()\n","#     indx = np.where(y == i)[0][0]\n","#     img = X[indx, :].reshape(8,8)\n","#     plt.imshow(img, cmap=plt.cm.gray_r, interpolation='nearest')\n","#     plt.title(str(i))\n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ply6OAX1nSx4","colab_type":"code","colab":{}},"source":["# n_components = 2\n","# perplexity = 30\n","\n","# tsne = TSNE(n_components=n_components, perplexity=perplexity, random_state=42)\n","# X_embedded = tsne.fit_transform(X)\n","\n","# plt.figure(figsize=(16,9))\n","# sns.scatterplot(X_embedded[:,0], X_embedded[:,1], hue=y, legend='full', palette=palette)\n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"daK_OdMdq3Kt","colab_type":"code","colab":{}},"source":["# from sklearn.decomposition import PCA\n","# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","\n","# pca = PCA(n_components=n_components)\n","# X_pca = pca.fit(X).transform(X)\n","\n","# pca = PCA(n_components=n_components)\n","# X_embedded_pca = pca.fit_transform(X)\n","\n","# lda = LinearDiscriminantAnalysis(n_components=n_components)\n","# X_embedded_lda = lda.fit(X, y).transform(X)\n","\n","# plt.figure(figsize=(20,9))\n","# plt.subplot(1,2,1)\n","# sns.scatterplot(X_embedded_pca[:,0], X_embedded_pca[:,1], hue=y, legend='full', palette=palette)\n","# plt.subplot(1,2,2)\n","# sns.scatterplot(X_embedded_lda[:,0], X_embedded_lda[:,1], hue=y, legend='full', palette=palette)\n","# plt.show()"],"execution_count":null,"outputs":[]}]}